{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq0M27tAa2SIWKClwMm4Uc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlibleft/TOM-projekt/blob/master/projekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EBBiIVmn5U8R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!\n",
        "!curl -O https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz\n",
        "!curl -O https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz\n",
        "!\n",
        "!tar -xf images.tar.gz\n",
        "!tar -xf annotations.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6X6IXAF6Qmp",
        "outputId": "75217bfe-88df-47f1-ebc4-d4becc4da0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  755M  100  755M    0     0  19.5M      0  0:00:38  0:00:38 --:--:-- 20.8M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 18.2M  100 18.2M    0     0  7376k      0  0:00:02  0:00:02 --:--:-- 7377k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCq5jJOM_Zwp",
        "outputId": "49488fdc-576b-4ccd-99f3-2eaf0474a52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynrrd\n",
        "!pip install SimpleITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KUpUgcqAU0-",
        "outputId": "8d1cc9f8-2fc8-49f1-81ac-1125cb851591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynrrd\n",
            "  Downloading pynrrd-1.0.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from pynrrd) (1.25.2)\n",
            "Collecting nptyping (from pynrrd)\n",
            "  Downloading nptyping-2.5.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pynrrd) (4.11.0)\n",
            "Installing collected packages: nptyping, pynrrd\n",
            "Successfully installed nptyping-2.5.0 pynrrd-1.0.0\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import SimpleITK as sitk\n",
        "\n",
        "'''\n",
        "# Funkcja do segmentacji aorty na podstawie progowania\n",
        "def threshold_segmentation(image_array, lower_threshold, upper_threshold):\n",
        "    # Ustaw piksele spoza zakresu na 0, a piksele w zakresie na 1\n",
        "    segmented_image=np.zeros(image_array.shape)\n",
        "    segmented_image = np.where((image_array >= lower_threshold) & (image_array <= upper_threshold), 1, 0)\n",
        "    return segmented_image\n",
        "'''\n",
        "\n",
        "def data_load(filepath):\n",
        "  # Ścieżka do pliku nrrd\n",
        "  nrrd_file_path = filepath\n",
        "\n",
        "  # Wczytaj plik nrrd\n",
        "  image = sitk.ReadImage(nrrd_file_path)\n",
        "\n",
        "  # Konwertuj obraz do numpy array\n",
        "  image_array = sitk.GetArrayFromImage(image)\n",
        "\n",
        "  # Wymiary obrazu\n",
        "  depth, height, width = image_array.shape\n",
        "  slice_index_list = []\n",
        "  pixel_range_list = []\n",
        "  for slice_index in range(depth):\n",
        "        slice_2d = image_array[slice_index, :, :]\n",
        "        min_pixel_value = slice_2d.min()\n",
        "        max_pixel_value = slice_2d.max()\n",
        "        pixel_range = (slice_2d.min(), slice_2d.max())\n",
        "        slice_index_list.append(slice_index)\n",
        "        pixel_range_list.append(pixel_range)\n",
        "  df = pd.DataFrame({'Przekrój': slice_index_list, 'Zakres wartości pikseli': pixel_range_list})\n",
        "\n",
        "\n",
        "  return slice_2d, image_array"
      ],
      "metadata": {
        "id": "_BYubbvW_bZP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#konwersja z nrrd na png, umieszczenie zdjec ct oraz ich segmentacji w osobnych folderach\n",
        "\n",
        "for i in range(1,19):\n",
        "  nrrd_file_path = f\"/content/drive/MyDrive/Dongyang/D{i}/D{i}.nrrd\"\n",
        "  slice_2d, image_array =data_load(nrrd_file_path)\n",
        "  depth, height, width = np.shape(image_array)\n",
        "  for j in range(depth):\n",
        "    plt.imshow(image_array[j], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f'/content/input_dir/D{i}-{j}.png')\n",
        "\n",
        "for i in range(1,19):\n",
        "  nrrd_file_path = f\"/content/drive/MyDrive/Dongyang/D{i}/D{i}.seg.nrrd\"\n",
        "  slice_2d, image_array =data_load(nrrd_file_path)\n",
        "  depth, height, width = np.shape(image_array)\n",
        "  for j in range(depth):\n",
        "    plt.imshow(image_array[j], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f'/content/target_dir/D{i}-{j}.seg.png')"
      ],
      "metadata": {
        "id": "bom3w1Khthlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input_dir-folder w ktorym trzymam zdjecia ct\n",
        "#target_dir w ktorym trzymam segmantacje zdjec\n",
        "\n",
        "import os\n",
        "input_dir = \"/content/input_dir\"\n",
        "target_dir = \"/content/target_dir\"\n",
        "\n",
        "#tworzenie listy ze ścieżkami do zdjęć\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_dir, fname)\n",
        "        for fname in os.listdir(target_dir)\n",
        "        if fname.endswith(\".png\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of samples:\", len(input_img_paths))\n",
        "\n",
        "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
        "    print(input_path, \"|\", target_path)"
      ],
      "metadata": {
        "id": "kHqTgRgfLnom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from keras.utils import load_img\n",
        "from PIL import ImageOps\n",
        "\n",
        "# wyswietlenie wybranego zdjeica i segmentacji\n",
        "display(Image('D3-64.png'))\n",
        "display(Image('D3-64.seg.png'))"
      ],
      "metadata": {
        "id": "TE4JE0BSEsuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_size = (160, 160)\n",
        "num_classes = 2\n",
        "batch_size = 32\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import io as tf_io\n",
        "\n",
        "\n",
        "def get_dataset(\n",
        "    batch_size,\n",
        "    img_size,\n",
        "    input_img_paths,\n",
        "    target_img_paths,\n",
        "    max_dataset_len=None,\n",
        "):\n",
        "    \"\"\"Returns a TF Dataset.\"\"\"\n",
        "\n",
        "    def load_img_masks(input_img_path, target_img_path):\n",
        "        input_img = tf_io.read_file(input_img_path)\n",
        "        input_img = tf_io.decode_png(input_img, channels=1)\n",
        "        input_img = tf_image.resize(input_img, img_size)\n",
        "        input_img = tf_image.convert_image_dtype(input_img, \"float32\")\n",
        "\n",
        "        target_img = tf_io.read_file(target_img_path)\n",
        "        target_img = tf_io.decode_png(target_img, channels=1)\n",
        "        target_img = tf_image.resize(target_img, img_size, method=\"nearest\")\n",
        "        target_img = tf_image.convert_image_dtype(target_img, \"uint8\")\n",
        "\n",
        "\n",
        "        target_img -= 1\n",
        "        return input_img, target_img\n",
        "\n",
        "    # For faster debugging, limit the size of data\n",
        "    if max_dataset_len:\n",
        "        input_img_paths = input_img_paths[:max_dataset_len]\n",
        "        target_img_paths = target_img_paths[:max_dataset_len]\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((input_img_paths, target_img_paths))\n",
        "    dataset = dataset.map(load_img_masks, num_parallel_calls=tf_data.AUTOTUNE)\n",
        "    return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "BEMt_hIQJKyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model\n",
        "model = get_model(img_size, num_classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xqXXLNnxJdwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Split our img paths into a training and a validation set\n",
        "val_samples = 1000\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "random.Random(1337).shuffle(target_img_paths)\n",
        "train_input_img_paths = input_img_paths[:-val_samples]\n",
        "train_target_img_paths = target_img_paths[:-val_samples]\n",
        "val_input_img_paths = input_img_paths[-val_samples:]\n",
        "val_target_img_paths = target_img_paths[-val_samples:]\n",
        "\n",
        "# Instantiate dataset for each split\n",
        "# Limit input files in `max_dataset_len` for faster epoch training time.\n",
        "# Remove the `max_dataset_len` arg when running with full dataset.\n",
        "train_dataset = get_dataset(\n",
        "    batch_size,\n",
        "    img_size,\n",
        "    train_input_img_paths,\n",
        "    train_target_img_paths,\n",
        "    max_dataset_len=1000,\n",
        ")\n",
        "valid_dataset = get_dataset(\n",
        "    batch_size, img_size, val_input_img_paths, val_target_img_paths\n",
        ")"
      ],
      "metadata": {
        "id": "Ilalqw23O53M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the model for training.\n",
        "# We use the \"sparse\" version of categorical_crossentropy\n",
        "# because our target data is integers.\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\"\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\", save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 50\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "3vq78GmxQIaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for all images in the validation set\n",
        "\n",
        "val_dataset = get_dataset(\n",
        "    batch_size, img_size, val_input_img_paths, val_target_img_paths\n",
        ")\n",
        "val_preds = model.predict(val_dataset)\n",
        "\n",
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = ImageOps.autocontrast(keras.utils.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "\n",
        "# Display results for validation image #10\n",
        "i = 10\n",
        "\n",
        "# Display input image\n",
        "display(Image(filename=val_input_img_paths[i]))\n",
        "\n",
        "# Display mask predicted by our model\n",
        "display_mask(i)  # Note that the model only sees inputs at 150x150."
      ],
      "metadata": {
        "id": "9d3ollcpQOJa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}